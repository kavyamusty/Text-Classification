{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC \n",
    "from scipy.spatial import distance\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score,cross_validate\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,\\\n",
    "classification_report,cohen_kappa_score,make_scorer,roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the training and testing data\n",
    "df1 = pd.read_csv('training.csv')\n",
    "df2 = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Encoding to quantitatively represent the topics\n",
    "encoding = {'topic' : \n",
    "            {'IRRELEVANT' : 0,\n",
    "             'ARTS CULTURE ENTERTAINMENT':1,\n",
    "             'BIOGRAPHIES PERSONALITIES PEOPLE':2,\n",
    "             'DEFENCE' : 3, \n",
    "             'DOMESTIC MARKETS' : 4, \n",
    "             'FOREX MARKETS' : 5, \n",
    "             'HEALTH' : 6, \n",
    "             'MONEY MARKETS' : 7,\n",
    "             'SCIENCE AND TECHNOLOGY' : 8, \n",
    "             'SHARE LISTINGS' : 9, \n",
    "             'SPORTS' :10,\n",
    "             }}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bag of words\n",
    "ngram_range = (1,2)\n",
    "min_df = 10    #When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "max_df = 1.   #max_df: When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold\n",
    "max_features = 1500\n",
    "#count = TfidfVectorizer()\n",
    "count= TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True,\n",
    "                        use_idf=True)\n",
    "bag_of_words = count.fit(df1['article_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Testing split - X and Y\n",
    "x_train = df1['article_words']\n",
    "y_train = df1['topic'].to_list()\n",
    "x_test = df2['article_words']\n",
    "y_test = df2['topic'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the testing and training\n",
    "x_train = bag_of_words.transform(x_train)\n",
    "x_test = bag_of_words.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=1, kernel='linear',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "model = classifier.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds = pd.read_csv(\"/home/nikita/Downloads/sample-data.csv\")\n",
    "def recommendation(test,y_predict,train_data,topic_dict,topic_list):\n",
    "    test_data = test.copy(deep=True)\n",
    "    test_data['topic'] = y_predict\n",
    "    #topic_list = [i for i in range(11)]\n",
    "    tf = TfidfVectorizer()\n",
    "    model = tf.fit(train_data['article_words'])\n",
    "    article_list = []\n",
    "    for t in topic_list:\n",
    "        if not test_data[test_data['topic']==t].empty and t != 'IRRELEVANT':        \n",
    "            tfidf_train = model.transform(train_data[train_data['topic']==t]['article_words']).toarray()\n",
    "            tfidf_test = model.transform(test_data[test_data['topic']==t]['article_words']).toarray()\n",
    "            test_article_number = test_data[test_data['topic']==t]['article_number'].tolist()\n",
    "            cosine = cosine_similarity(tfidf_test,tfidf_train)\n",
    "            cosine = np.sort(cosine)\n",
    "            suggested_list = np.argsort(cosine[:,-1])[-10:].tolist()\n",
    "            article_number = [test_article_number[i] for i in suggested_list]\n",
    "            article_list += article_number\n",
    "            article_number = \",\".join([str(test_article_number[i]) for i in suggested_list])         \n",
    "            print(f\"For topic {t} recommending article {article_number}\")\n",
    "    y_rec_true = [(test[test['article_number']==i]['topic']).tolist()[0] for i in article_list]\n",
    "    y_rec_predict = [(test_data[test_data['article_number']==i]['topic']).tolist()[0] for i in article_list]\n",
    "    return y_rec_true,y_rec_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For topic ARTS CULTURE ENTERTAINMENT recommending article 9703,9830,9933,9952\n",
      "For topic BIOGRAPHIES PERSONALITIES PEOPLE recommending article 9896,9526,9988,9940\n",
      "For topic DEFENCE recommending article 9607,9770,9616,9670,9559,9759,9987,9576,9773\n",
      "For topic DOMESTIC MARKETS recommending article 9640,9989\n",
      "For topic FOREX MARKETS recommending article 9671,9565,9530,9529,9977,9551,9986,9682,9588,9798\n",
      "For topic HEALTH recommending article 9982,9947,9810,9661,9873,9621,9929,9807,9833,9926\n",
      "For topic MONEY MARKETS recommending article 9961,9808,9678,9766,9725,9555,9761,9853,9634,9586\n",
      "For topic SHARE LISTINGS recommending article 9562,9666,9715,9601,9518\n",
      "For topic SPORTS recommending article 9787,9992,9791,9754,9630,9752,9608,9513,9520,9800\n"
     ]
    }
   ],
   "source": [
    "topic_dict = {encoding['topic'][k] : k for k in encoding['topic']}\n",
    "topic_dict\n",
    "y_rec_true,y_rec_predict = recommendation(df2,y_predict,df1,topic_dict,encoding['topic'])\n",
    "d = {'y_rec_true':y_rec_true,'y_rec_predict':y_rec_predict}\n",
    "# Dataframe of the recommendation topic and the true topic\n",
    "df_rec = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  precision    recall  f1-score   support\n",
      "\n",
      "      ARTS CULTURE ENTERTAINMENT       0.50      1.00      0.67         2\n",
      "BIOGRAPHIES PERSONALITIES PEOPLE       0.75      0.60      0.67         5\n",
      "                         DEFENCE       0.78      1.00      0.88         7\n",
      "                DOMESTIC MARKETS       0.00      0.00      0.00         0\n",
      "                   FOREX MARKETS       0.60      0.60      0.60        10\n",
      "                          HEALTH       0.80      1.00      0.89         8\n",
      "                      IRRELEVANT       0.00      0.00      0.00        10\n",
      "                   MONEY MARKETS       0.50      0.56      0.53         9\n",
      "          SCIENCE AND TECHNOLOGY       0.00      0.00      0.00         1\n",
      "                  SHARE LISTINGS       0.60      1.00      0.75         3\n",
      "                          SPORTS       0.90      1.00      0.95         9\n",
      "\n",
      "                        accuracy                           0.67        64\n",
      "                       macro avg       0.49      0.61      0.54        64\n",
      "                    weighted avg       0.58      0.67      0.62        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/apple/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_rec_true, y_rec_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
